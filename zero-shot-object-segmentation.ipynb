{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7018abc7",
   "metadata": {},
   "source": [
    "# GenAI \n",
    "\n",
    "This notebook shows how do use different Generative AI techniques such as Zero Shot learning for object detection and segmentation, as well as prompted inpainting\n",
    "\n",
    "Developed for reinvent by: Gonzalo Barbeito, Romil Shah, Andrea Montanari, Derek Graber, Matt Polloc, Junjie Tang, Fabian Benitez-Quiroz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ece91b-32b7-43a4-a484-37f9c46e594d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- An instance or notebook with G5 instance\n",
    "- A python environment from the requirements.txt, eg conda create -n summit-q4-2023 python=3.10 && pip install -r requirements.txt  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2c1d0",
   "metadata": {},
   "source": [
    "![image.png](./assets/0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317d6dd-b4bc-4357-9d40-0fee3ed514c7",
   "metadata": {},
   "source": [
    "## Zero-learning foundational models (Object Detection)\n",
    "\n",
    "Zero-shot learning is a Generative AI technique that allows a model to perform a machine learning task (such as object detection of a given class) without any specific training for some classes. \n",
    "\n",
    "Modern zero-shot learning in images allows you to find or segment objects by just using a single prompt. For example, algorithms such as [Grouding Dino](https://github.com/IDEA-Research/GroundingDINO) works by using transformer-based detector and pre-training technique so it learns the association between language and vision modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5efd019",
   "metadata": {},
   "source": [
    "### Example | Find objects using Grounding Dino\n",
    "\n",
    "In the cell below we can search for street objects such as stop signs and traffic lights just by prompting for it. \n",
    "We have built a set of of functions to abstract this functionality.\n",
    "\n",
    "1. `GenAiModels` is just a holder for an inference pipeline based on [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything). This pipeline chains the following elements in succession:\n",
    "    - [Grounding Dino](https://github.com/IDEA-Research/GroundingDINO): an object detection model. It uses a prompt in natural language as input to detect objects for which it has not been explicitly trained (zero-shot learning)\n",
    "    - [SamProcessor](https://huggingface.co/docs/transformers/main/model_doc/sam#transformers.SamProcessor): an image processor used for preparing images to be used with the SAM model\n",
    "    - [SAM Model](https://github.com/facebookresearch/segment-anything): a model capable of segmenting objects in an image using bounding boxes or points as inputs, \n",
    "    - [StableDiffusion](https://github.com/Stability-AI/stablediffusion): a model used to generate images based on text prompts. Specifically for this use case, we will be using a model capable of inpainting, which replaces a specific part of an image making sense in context.\n",
    "2. `Prompts` object holds the prompts to select and replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements from requirements.txt \n",
    "import subprocess\n",
    "try:\n",
    "    from groundingdino.util.inference import load_model\n",
    "except:\n",
    "    subprocess.call(\"rm GroundingDINO -rf\", shell=True) \n",
    "    subprocess.call(\"git clone https://github.com/IDEA-Research/GroundingDINO.git && cd GroundingDINO/ && pip install -e . -q && cd .. \", shell=True) \n",
    "    subprocess.call(\"wget -q weights  https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth -O ./weights/groundingdino_swinb_cogcoor.pth\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel to take effect of grounding dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1cced-0d3b-41ff-b6b0-bf57b7beb458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Import basic set of classes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as python_image\n",
    "from PIL import Image\n",
    "from utils import (\n",
    "    GenAiModels,\n",
    "    load_image_func,\n",
    "    Prompts,\n",
    "    natural_sort,\n",
    "    plot_images,    \n",
    ")\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Create the GenAImodels class to do object detection and segmentation\n",
    "genai_models = GenAiModels()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9fa090",
   "metadata": {},
   "source": [
    "### Import data from the object detection pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"./assets/northwest.jpg\"\n",
    "from PIL import Image\n",
    "image_tmp = load_image_func(img_url, 512)\n",
    "image_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tmp = load_image_func(img_url, 512)\n",
    "\n",
    "# define a set of prompts\n",
    "prompt_object = Prompts(search_prompt=\"house on the right\")\n",
    "# execute the prompts for object detection\n",
    "_, image_tmp = genai_models.prompt_segmentation(image_tmp, prompt_object)\n",
    "image_tmp.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78290ca5-e471-4525-8dbe-38a60468314a",
   "metadata": {},
   "source": [
    "## Perform segmentation using segment anything\n",
    "\n",
    "Similarly, we can use a combination of GroundingDino in tandem with GenerativeAI segmentation model such as [SegmentAnything](https://github.com/facebookresearch/segment-anything) to perform detailed segmentation without training for it. Similar to zero-shot object detection methods, it finds the relatioship between language and fine grain visual segmentation. This methods are usually trained using over 10M images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf06ca-2dcf-4890-9dbc-42de496debd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_tmp = load_image_func(img_url, 512)\n",
    "prompt_object = Prompts(search_prompt=\"stop sign. traffic lights. house on the right\")\n",
    "image_tmp, _ =  genai_models.prompt_segmentation(image_tmp, prompt_object)\n",
    "image_tmp.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56f3dd-9a3b-4169-9f44-53e49fb68065",
   "metadata": {},
   "source": [
    "## Example: Use GenAI to blend certain area with the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245b490-7188-4b0a-a597-86189de29190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_tmp = load_image_func(img_url, 512)\n",
    "prompt_object = Prompts(search_prompt=\"stop sign. cable. traffic lights. house on the right.\")\n",
    "image_tmp = genai_models.remove_from_image(image_tmp, prompt_object)\n",
    "image_tmp.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ea16f-7809-4c8f-aa2e-477eb30b8337",
   "metadata": {},
   "source": [
    "### Task: Use your own prompt to remove objects from the image \n",
    "\n",
    "Use your own prompts to find and remove parts of the image. Some possible prompts are car and house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4b1e1-83cb-4593-b01d-483ed70ea173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = load_image_func(img_url, 512)\n",
    "prompt_object = Prompts(search_prompt=\"car\")\n",
    "image_tmp = genai_models.remove_from_image(image, prompt_object)\n",
    "image_tmp.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7944c4c-4c9a-4f1a-9993-58ddfb513ff8",
   "metadata": {},
   "source": [
    "## Replace an object using Stable Diffusion Inpainting\n",
    "\n",
    "Traditional Inpainting algorithms deal with replacing information from an image using the context of the rest of the image. This is used in many phones nowadays to remove objects from picture or photobombing. Generative AI methods push this boundary further by replacing a selected area with an object described inside a prompt. For example, you can replace the stree with a flooded street.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72124029-27d3-48c2-aa13-8fa854e65860",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = load_image_func(img_url, 512)\n",
    "prompt_object = Prompts(search_prompt=\"street\",\n",
    "                       replace_prompt=\"flooded street. 4k\")\n",
    "image_tmp = genai_models.search_replace(image, prompt_object, seed=50)\n",
    "image_tmp.convert(\"RGB\")\n",
    "plot_images([image, image_tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Use zero shot learning to create a verification job\n",
    "\n",
    "Some customers want to ease the burden of a private workforce annotation. For example, Amazon facilites want to create a way to find the truck, trailer, license plate, lets see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"./assets/truck2.webp\"\n",
    "\n",
    "image_tmp = load_image_func(img_url, 1024)\n",
    "\n",
    "# define a set of prompts\n",
    "prompt_1 = \"truck. car license plates. trailer\"\n",
    "prompt_2 = \"trailer\"\n",
    "prompt_3 = \"back part of a truck\"\n",
    "prompt_4 = prompt_3 + \".car license plates\"\n",
    "prompt_object = Prompts(search_prompt=prompt_2)\n",
    "# execute the prompts for object detection\n",
    "_, image_tmp = genai_models.prompt_segmentation(image_tmp, prompt_object)\n",
    "image_tmp.convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70092e-1b98-43bc-b1ed-82bffd03dc71",
   "metadata": {},
   "source": [
    "## Prompted Segmention in a group of images\n",
    "\n",
    "We can scale the concept of segmentation to a video by using the same segmetation prompt across a set of frames. Let's use the images inside the rosbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04464a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_list = natural_sort(glob.glob('images/*.png'))\n",
    "search_prompt=\"vehicle lane\"\n",
    "prompt_object = Prompts(search_prompt=search_prompt)\n",
    "generated_list = genai_models.prompt_segmentation_list(images_list[:20], prompt_object)\n",
    "generated_list[0].save(\"out.gif\", save_all=True, append_images=generated_list[1:], duration=200, loop=0)\n",
    "display(python_image('out.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a88a8-5ad8-49e7-b9f0-bb62f0a71f7e",
   "metadata": {},
   "source": [
    "## Replace area with a new texture\n",
    "\n",
    "In the example below we are selecting \"vehicle lane\" and replacing it across al frames with a \"flooded street\". We can generate also a reconstruction of the video by attaching the generated frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10ded0-3d14-4bec-ad59-5ea7ef43b0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_list = natural_sort(glob.glob('images/*.png'))\n",
    "\n",
    "search_prompt = \"vehicle lane\"\n",
    "replace_prompt = \"flooded street. 4k.\"\n",
    "prompt_object = Prompts(search_prompt=search_prompt,\n",
    "                        replace_prompt=replace_prompt,\n",
    "                       negative_prompt=\"text. low quality. car\")\n",
    "\n",
    "generated_list_1 = genai_models.search_replace_list(images_list[:10], prompt_object, temporal_smoothing=False)\n",
    "\n",
    "# result_image = prompt_segmentation(image, model, prompt_object, 3)\n",
    "generated_list_1[0].save(\"out.gif\", save_all=True, append_images=generated_list_1[1:], duration=200, loop=0)\n",
    "display(python_image('out.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369f379-190c-4c4b-ae0a-ddfa785c2545",
   "metadata": {},
   "source": [
    "## Generate same video but this time using temporal information\n",
    "\n",
    "We can also use temporal information to produce a smooth transition across consecutive frames. In the example below, we are replacing vehicle lane with a \"snowy street\"\n",
    "\n",
    "Algorithms for optical flow need to learn how to:\n",
    "  1. Find correspondence between points.\n",
    "  2. Compute the relative offsets between points.\n",
    "  3. Predict flow across large regions of space, even to parts of the image that lack texture for correspondence.\n",
    "1. The learned procedure needs to generalize to real data, which means it needs to work for objects and textures that were not seen in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/optical-flow1.jpg?modified=12345678) ![](./assets/optical-flow2.jpg?modified=12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0bd54-9b85-4eca-902d-3190132d7ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_list = natural_sort(glob.glob('./images/*.png'))\n",
    "\n",
    "search_prompt=\"vehicle lane\"\n",
    "replace_prompt = \"snowy street, 4k\"\n",
    "prompt_object = Prompts(search_prompt=search_prompt,\n",
    "                        replace_prompt=replace_prompt,\n",
    "                        negative_prompt=\"low quality. cars. car. vehicle. car rear.\")\n",
    "\n",
    "generated_list = genai_models.search_replace_list(images_list[:15], \n",
    "                                                  prompt_object, \n",
    "                                                  temporal_smoothing=True, \n",
    "                                                  fancy_flow=False,\n",
    "                                                  seed = 18)\n",
    "generated_list[0].save(\"out_temp.gif\", save_all=True, append_images=generated_list[1:], duration=200, loop=0)\n",
    "\n",
    "\n",
    "display(python_image('out_temp.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GenAI to get the optical flow\n",
    "\n",
    "We can also use Perceiver-IO (https://arxiv.org/pdf/2107.14795.pdf) to produce the flow from image to image\n",
    "\n",
    "![image](./assets/perceiver_io.jpg?modified=12345678)\n",
    "\n",
    "Use the same function but turn fancy_flow from False to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "frame_1 = Image.open(images_list[idx])\n",
    "frame_2 = Image.open(images_list[idx+1])\n",
    "\n",
    "rendered_optical_flow = genai_models.optical_flow_pipeline((frame_1 .resize((500,500)), frame_2.resize((500,500))), render=True)\n",
    "Image.fromarray(rendered_optical_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = natural_sort(glob.glob('./images/*.png'))\n",
    "\n",
    "search_prompt=\"vehicle lane\"\n",
    "replace_prompt = \"snowy street, 4k\"\n",
    "prompt_object = Prompts(search_prompt=search_prompt,\n",
    "                        replace_prompt=replace_prompt,\n",
    "                        negative_prompt=\"low quality. cars. car. vehicle. car rear.\")\n",
    "\n",
    "generated_list = genai_models.search_replace_list(images_list[:15], \n",
    "                                                  prompt_object, \n",
    "                                                  temporal_smoothing=True, \n",
    "                                                  fancy_flow=True,\n",
    "                                                  seed = 18)\n",
    "generated_list[0].save(\"out_temp_fancy.gif\", save_all=True, append_images=generated_list[1:], duration=200, loop=0)\n",
    "\n",
    "\n",
    "display(python_image('out_temp_fancy.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45625-33ab-4996-9b93-82e99351c2c8",
   "metadata": {},
   "source": [
    "## Save images as png and run the object detection pipeline again\n",
    "\n",
    "We can save the generated images and trigger the object detection pipeline as in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55514081-0f7d-4aba-98cd-ef7d82415330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "new_dir = f\"output/{str(uuid.uuid4())}/\"\n",
    "print(new_dir)\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for k1, image in enumerate(generated_list):\n",
    "    file_name = f\"{new_dir}{str(k1).rjust(5,'0')}.png\"\n",
    "    print(file_name)\n",
    "    image.save(file_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
